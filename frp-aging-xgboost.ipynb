{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b467c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 25-04-07\n",
    "# - Changed stratification method to bins, which is suited for regression\n",
    "# - Defined functions for code organization and conciseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51bad64-2c7a-4628-8a46-6b20c5ba53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from contextlib import suppress\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import r2_score, PredictionErrorDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, XGBRegressor\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17230632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record and display execution start time\n",
    "start_time = time.time()\n",
    "now = datetime.now()\n",
    "print(now.strftime(\"%d/%m/%Y %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(target, min_target_counts=1, cols_to_drop=[]):\n",
    "    \"\"\"Read and preprocess a .CSV file into a filtered pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        target (string): Name of the target property (must match a column name\n",
    "            in the .CSV file)\n",
    "        min_target_counts (int | float): Minimum count threshold for target\n",
    "            values. Rows with values appearing fewer times are dropped.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Filtered dataset with only relevant columns. Rows\n",
    "            with values appearing fewer times are dropped.\n",
    "    \n",
    "    Notes:\n",
    "        The .CSV file path is hardcoded in this version and not\n",
    "            user-configurable\n",
    "        XGBoost is sparsity-aware. No need to drop missing values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get .CSV file path\n",
    "    main_path = str(os.getcwd())\n",
    "    file = main_path + '\\\\Entradas\\\\degrad_dataset.csv'\n",
    "\n",
    "    # Read .CSV as pandas dataframe\n",
    "    df = pd.read_csv(file, delimiter=';')\n",
    "\n",
    "    # Drop columns that are not important for the analysis\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Remove unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    # Filters target property values that appear less than 4 times\n",
    "    value_counts = df[target].value_counts()\n",
    "    valid_values = value_counts[value_counts > min_target_counts - 1].index\n",
    "    df = df[df[target].isin(valid_values)]\n",
    "\n",
    "    # Encoding categorical features\n",
    "    pass\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abs_error(y_test, y_pred):  \n",
    "    \"\"\"Calculate the maximum signed absolute error between predicted and actual\n",
    "        values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (pandas.DataFrame): Actual values.\n",
    "        y_pred (numpy.ndarray): Predicted values from the model.\n",
    "    \n",
    "        Returns:\n",
    "            float: Maximum signed absolute error (y_pred - y_test), rounded to\n",
    "                3 decimals.\n",
    "        \n",
    "        Notes:\n",
    "            Positive values indicate overprediction, negative underprediction.\n",
    "            Both inputs must have the same length.    \n",
    "        \n",
    "        Example:\n",
    "        \\\\>>> y_test = pd.DataFrame([1.2, 3.4, 5.6])\n",
    "        \\\\>>> y_pred = np.array([1.0, 3.5, 5.2])\n",
    "        \\\\>>> get_abs_error(y_test, y_pred)\n",
    "        -0.4\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test = y_test.tolist()\n",
    "    a = []\n",
    "    for i in range(len(y_test)):\n",
    "        a.append((y_pred[i] - y_test[i]))\n",
    "        \n",
    "    abs_error=0\n",
    "    if max(abs(i) for i in a) == max(a):\n",
    "        abs_error = max(a)\n",
    "    else:\n",
    "        abs_error = min(a)\n",
    "\n",
    "    return round(abs_error, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b960d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_error(y_test, y_pred):\n",
    "    \"\"\"Calculate the maximum signed relative error between predicted and actual\n",
    "        values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (pandas.DataFrame): Actual values.\n",
    "        y_pred (numpy.ndarray): Predicted values from the model.\n",
    "    \n",
    "        Returns:\n",
    "            float: Maximum signed relative error ((y_pred - y_test) / y_test),\n",
    "                rounded to 3 decimals.\n",
    "        \n",
    "        Notes:\n",
    "            Positive values indicate overprediction, negative underprediction.\n",
    "            Both inputs must have the same length.\n",
    "        \n",
    "        Example:\n",
    "        \\\\>>> y_test = pd.DataFrame([1.2, 3.4, 5.6])\n",
    "        \\\\>>> y_pred = np.array([1.0, 3.5, 5.2])\n",
    "        \\\\>>> get_rel_error(y_test, y_pred)\n",
    "        -0.167\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test = y_test.tolist()\n",
    "    a = []\n",
    "    for i in range(len(y_test)):\n",
    "        a.append((y_pred[i] - y_test[i])/y_test[i])\n",
    "        \n",
    "    rel_error=0\n",
    "    if max(abs(i) for i in a) == max(a):\n",
    "        rel_error = max(a)\n",
    "    else:\n",
    "        rel_error = min(a)\n",
    "\n",
    "    return round(rel_error, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(y_test, y_pred):\n",
    "    \"\"\"Calculate the mean absolute error (MAE) between predicted and actual values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (pandas.DataFrame): Actual values.\n",
    "        y_pred (numpy.ndarray): Predicted values from the model.\n",
    "    \n",
    "        Returns:\n",
    "            float: MAE (Σ(|y_pred - y_test|) / len(y_test)), rounded to 3 decimals.\n",
    "        \n",
    "        Note:\n",
    "            Both inputs must have the same length.\n",
    "        \n",
    "        Example:\n",
    "        \\\\>>> y_test = pd.DataFrame([1.2, 3.4, 5.6])\n",
    "        \\\\>>> y_pred = np.array([1.0, 3.5, 5.2])\n",
    "        \\\\>>> get_mae(y_test, y_pred)\n",
    "        0.233\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test = y_test.tolist()\n",
    "    a = 0\n",
    "    for i in range(len(y_test)):\n",
    "        a = a + abs(y_pred[i] - y_test[i])\n",
    "        \n",
    "    mae = a / len(y_test)\n",
    "\n",
    "    return round(mae, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y_test, y_pred):\n",
    "    \"\"\"Calculate the root mean squared error (RMSEA) between predicted and\n",
    "        actual values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (pandas.DataFrame): Actual values.\n",
    "        y_pred (numpy.ndarray): Predicted values from the model.\n",
    "    \n",
    "        Returns:\n",
    "            float: RMSE ((Σ(|y_pred - y_test|)² / len(y_test))^0.5), rounded\n",
    "                to 3 decimals.\n",
    "        \n",
    "        Note:\n",
    "            Both inputs must have the same length.\n",
    "        \n",
    "        Example:\n",
    "        \\\\>>> y_test = pd.DataFrame([1.2, 3.4, 5.6])\n",
    "        \\\\>>> y_pred = np.array([1.0, 3.5, 5.2])\n",
    "        \\\\>>> get_rmse(y_test, y_pred)\n",
    "        0.265\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test = y_test.tolist()\n",
    "    a = 0\n",
    "    for i in range(len(y_test)):\n",
    "        a = a + (y_pred[i] - y_test[i]) ** 2\n",
    "        \n",
    "    rmse = np.sqrt(a / len(y_test))\n",
    "\n",
    "    return round(rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e326f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r2(y_test, y_pred):\n",
    "    \"\"\"Calculate the coefficient of determination (or R² score) of predicted\n",
    "        values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (pandas.DataFrame): Actual values.\n",
    "        y_pred (numpy.ndarray): Predicted values from the model.\n",
    "    \n",
    "        Returns:\n",
    "            float: R² score (1 - RSS/TSS), rounded to 3 decimals.\n",
    "        \n",
    "        Note:\n",
    "            RSS: Residual sum of squares (Σ(y_pred - y_test)²).\n",
    "            TSS: Total sum of squares (Σ(mean - y_test)²), i.e., variability of\n",
    "                the actual data.\n",
    "            An R² score equal to 1 indicates a perfect fit between predicted and\n",
    "                actual values. An R² equal to 0 means the prediction is no better\n",
    "                than the mean. A negative R² indicates the prediction is worse\n",
    "                than the mean.\n",
    "            Both inputs must have the same length.\n",
    "        \n",
    "        Example:\n",
    "        \\\\>>> y_test = pd.DataFrame([1.2, 3.4, 5.6])\n",
    "        \\\\>>> y_pred = np.array([1.0, 3.5, 5.2])\n",
    "        \\\\>>> get_r2(y_test, y_pred)\n",
    "        0.978\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test = y_test.tolist()\n",
    "    mean = sum(y_test) / len(y_test)\n",
    "    rss = 0  # Residual sum of squares\n",
    "    tss = 0  # Total sum of squares\n",
    "    for i in range(len(y_test)):\n",
    "        rss = rss + (y_pred[i] - y_test[i]) ** 2\n",
    "        tss = tss + (mean - y_test[i]) ** 2\n",
    "\n",
    "    r2 = 1 - rss / tss\n",
    "\n",
    "    return round(r2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "05aa7b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def run(n_splits=10):\n",
    "    \"\"\"...\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        print(i)\n",
    "\n",
    "run()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598adc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_error_list = []\n",
    "max_rel_error_list = []\n",
    "MAE_list = []\n",
    "RMSE_list = []\n",
    "R2_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8091a23-5ff8-4114-9c00-60c8d99a3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target='Tensile modulus retention'\n",
    "min_target_counts = 1\n",
    "cols_to_drop = ['Author',\n",
    "                'Isophtalic polyester resin',\n",
    "                'Orthophtalic polyester resin',\n",
    "                'Vinylester resin',\n",
    "                'Phenolic resin',\n",
    "                'Epoxy resin',\n",
    "                'Glass fiber',\n",
    "                'Carbon fiber',\n",
    "                'Pultrusion',\n",
    "                'Hand lay-up',\n",
    "                'Filament winding',\n",
    "                'VARTM',\n",
    "                'Coupon descr.',\n",
    "                'Aging effect',\n",
    "                'Steady condition',\n",
    "                'Cyclic condition',\n",
    "                'Immersion',\n",
    "                'Moisture',\n",
    "                'Presence of salts',\n",
    "                #'Relative humidity',\n",
    "                #'Sustained loading',\n",
    "                'Exposure time (hours)',\n",
    "                'Min. exposure temperature (ºC)',\n",
    "                'Max. exposure temperature (ºC)'#,\n",
    "                #'Residual tensile modulus (GPa)',\n",
    "                #'Unaged tensile modulus (GPa)',\n",
    "                ]\n",
    "\n",
    "df = dataset(target=target,\n",
    "             min_target_counts=min_target_counts,\n",
    "             cols_to_drop=cols_to_drop)\n",
    "\n",
    "display(df.head())\n",
    "df.info()\n",
    "df[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98478a97",
   "metadata": {},
   "source": [
    "### Random state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ad4a4-b925-4366-b3f7-284740032d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573316f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                         ))\n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8117ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 0.3, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b43531",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb89f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20649cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "abs_error = get_abs_error(y_test, y_pred)\n",
    "\n",
    "abs_error_list.append(abs_error)\n",
    "print(\"Maximum error = \", round(abs_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b41722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum relative error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_rel_error_list.append(max_error)\n",
    "print(\"Maximum relative error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b5fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85682442",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb9ae6",
   "metadata": {},
   "source": [
    "For tree model, \"Importance type\" can be defined as:\n",
    "\n",
    "- ‘weight’: the number of times a feature is used to split the data across all trees.\n",
    "- ‘gain’: the average gain across all splits the feature is used in.\n",
    "- ‘cover’: the average coverage across all splits the feature is used in.\n",
    "- ‘total_gain’: the total gain across all splits the feature is used in.\n",
    "- ‘total_cover’: the total coverage across all splits the feature is used in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "with suppress(ValueError): \n",
    "    plot_importance(xgboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "xgboost_model.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_tree(xgboost_model, ax=ax, num_trees=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(xgboost_model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650e734",
   "metadata": {},
   "source": [
    "### Random state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de883aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17baa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                        #  , objective='reglinear',\n",
    "                         ))\n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f61f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05dec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f52d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b156f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i]))\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_error_list.append(max_error)\n",
    "print(\"Maximum error = \", round(max_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e55cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum relative error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_rel_error_list.append(max_error)\n",
    "print(\"Maximum relative error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f858174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "xgboost_model.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37cf3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_tree(xgboost_model, ax=ax, num_trees=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(xgboost_model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d41b02",
   "metadata": {},
   "source": [
    "### Random state = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6592feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c240a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                        #  , objective='reglinear',\n",
    "                         ))\n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb96e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea076632",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1492998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i]))\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_error_list.append(max_error)\n",
    "print(\"Maximum error = \", round(max_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdd2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum relative error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_rel_error_list.append(max_error)\n",
    "print(\"Maximum relative error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b779ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e38530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff663688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "xgboost_model.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_tree(xgboost_model, ax=ax, num_trees=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ba9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(xgboost_model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca648f",
   "metadata": {},
   "source": [
    "### Random state = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec78427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe461c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                        #  , objective='reglinear',\n",
    "                         )) \n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0abce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ef195",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f1ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83598e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_error_list.append(max_error)\n",
    "print(\"Maximum error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbcdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60550458",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202d07f",
   "metadata": {},
   "source": [
    "### Random state = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39165e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d126f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                        #  , objective='reglinear',\n",
    "                         ))\n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8eeb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e03e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9387a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cdc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i]))\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_error_list.append(max_error)\n",
    "print(\"Maximum error = \", round(max_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum relative error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_rel_error_list.append(max_error)\n",
    "print(\"Maximum relative error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f630bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ce2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "xgboost_model.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_tree(xgboost_model, ax=ax, num_trees=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(xgboost_model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373e28e",
   "metadata": {},
   "source": [
    "### Random state = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f70ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                        #  , objective='reglinear',\n",
    "                         ))\n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3880416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92738742",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04baa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965fddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35549cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i]))\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_error_list.append(max_error)\n",
    "print(\"Maximum error = \", round(max_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e180b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum relative error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_rel_error_list.append(max_error)\n",
    "print(\"Maximum relative error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ed6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931565b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "xgboost_model.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff55a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_tree(xgboost_model, ax=ax, num_trees=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb5208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(xgboost_model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a3439",
   "metadata": {},
   "source": [
    "### Random state = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34cc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd209b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                        #  , objective='reglinear',\n",
    "                         ))\n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33103a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674108a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i]))\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_error_list.append(max_error)\n",
    "print(\"Maximum error = \", round(max_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum relative error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_rel_error_list.append(max_error)\n",
    "print(\"Maximum relative error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef3bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cce6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "xgboost_model.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e204c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_tree(xgboost_model, ax=ax, num_trees=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328432d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(xgboost_model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13704c45",
   "metadata": {},
   "source": [
    "### Random state = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b018bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51cf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                        #  , objective='reglinear',\n",
    "                         ))\n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d85896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ac8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a57c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c75ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i]))\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_error_list.append(max_error)\n",
    "print(\"Maximum error = \", round(max_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc45fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum relative error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_rel_error_list.append(max_error)\n",
    "print(\"Maximum relative error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75846c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b0a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "xgboost_model.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082cc333",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_tree(xgboost_model, ax=ax, num_trees=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(xgboost_model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278174b4",
   "metadata": {},
   "source": [
    "### Random state = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88430e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac147f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                        #  , objective='reglinear',\n",
    "                         )) \n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ee22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f453286",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a95dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55340e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i]))\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_error_list.append(max_error)\n",
    "print(\"Maximum error = \", round(max_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36069504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum relative error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_rel_error_list.append(max_error)\n",
    "print(\"Maximum relative error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10debb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaacdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b07bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "xgboost_model.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_tree(xgboost_model, ax=ax, num_trees=500)\n",
    "    #plt.savefig(str(os.getcwd()) + '\\\\Saídas\\\\tree_' + now.strftime(\"%d-%m-%Y_%H-%M-%S\") + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51586545",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(xgboost_model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2643728b",
   "metadata": {},
   "source": [
    "### Random state = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a63cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables from target\n",
    "X = df.drop(columns='Tensile modulus retention')\n",
    "y = df['Tensile modulus retention']\n",
    "\n",
    "# Bin the continuous target into categories for stratification\n",
    "bins = pd.qcut(y, q=5, duplicates='drop')  # You can change q to another number (e.g. 5 or 8) if needed\n",
    "\n",
    "# Split data in training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=bins, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with transformations to be passed to the training pipeline\n",
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=0, booster='gbtree'\n",
    "                         , base_score=0.9#, n_estimators=2000\n",
    "                         , eval_metric=r2_score#, early_stopping_rounds=50, eval_set=[(X_test, y_test)]\n",
    "                        #  , objective='reglinear',\n",
    "                         )) \n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e35bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search range of the hyperparameters to be tuned\n",
    "search_space = {\n",
    "    # 'clf__base_score': Real(0.0, 1000.0),\n",
    "    'clf__max_depth': Integer(2, 8),\n",
    "    'clf__n_estimators': Integer(50, 2000),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.6, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.6, 1.0),\n",
    "    # 'clf__colsample_bylevel': Real(0.1, 1.0),\n",
    "    # 'clf__colsample_bynode': Real(0.1, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 1.0), # L1 regularization\n",
    "    # 'clf__reg_lambda': Real(0.0, 5.0),\n",
    "    # 'clf__gamma': Real(0.0, 2.0),\n",
    "    # 'clf__min_child_weight': Real(1.0, 10.0)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=5, n_iter=60\n",
    ", scoring='r2', error_score=\"raise\"\n",
    " , random_state=0, return_train_score=True, n_jobs=6, n_points=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test\")\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e97db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(X_test)\n",
    "\n",
    "print(\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b148c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i]))\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_error_list.append(max_error)\n",
    "print(\"Maximum error = \", round(max_error, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d747b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum relative error of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append((a[i] - y_pred[i])/a[i])\n",
    "    \n",
    "if abs(max(b)) > abs(max(b)):\n",
    "    max_error = max(b)\n",
    "else:\n",
    "    max_error = min(b)\n",
    "\n",
    "max_rel_error_list.append(max_error)\n",
    "print(\"Maximum relative error = \", 100 * round(max_error, 2), \" %\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error (MAE) of prediction in relation to the test data\n",
    "a = y_test.tolist()\n",
    "avg = sum(a) / len(a)\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + abs(a[i] - y_pred[i])\n",
    "    c = c + abs(a[i] - avg)\n",
    "    \n",
    "MAE_pred = b / len(a)\n",
    "MAE_avg = c / len(a)\n",
    "MAE_list.append(MAE_pred)\n",
    "print(\"Prediction MAE =\", MAE_pred)\n",
    "print(\"Average MAE =\", MAE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd37b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (RMSE) of the prediction\n",
    "\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(len(a)):\n",
    "    b = b + (a[i] - y_pred[i]) ** 2\n",
    "    c = c + (a[i] - avg) ** 2\n",
    "    \n",
    "RMSE_pred = np.sqrt(b / len(a))\n",
    "RMSE_avg = np.sqrt(c / len(a))\n",
    "RMSE_list.append(RMSE_pred)\n",
    "print(\"Prediction RMSE =\", RMSE_pred)\n",
    "print(\"Average RMSE =\", RMSE_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R² score of the prediction\n",
    "\n",
    "a = y_test.tolist()\n",
    "RSS = 0             # Sum of the square of the residuals of the prediction\n",
    "TSS = 0             # Sum of the square of the residuals of the average\n",
    "for i in range(len(a)):\n",
    "    RSS = RSS + (a[i] - y_pred[i]) ** 2\n",
    "    TSS = TSS + (a[i] - avg) ** 2\n",
    "\n",
    "R2 = 1 - RSS / TSS\n",
    "R2_list.append(R2)\n",
    "print(\"Average =\", avg, \"\\nR² =\", R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PredictionErrorDisplay.from_predictions(y_test, y_pred, kind=\"actual_vs_predicted\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "xgboost_step = opt.best_estimator_.steps[1]\n",
    "xgboost_model = xgboost_step[1]\n",
    "\n",
    "xgboost_model.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_tree(xgboost_model, ax=ax, num_trees=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3929f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(xgboost_model, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e740f1",
   "metadata": {},
   "source": [
    "### Score lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41786a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max. error:\", max_error_list)\n",
    "print(\"\\nMax. relative error:\", max_rel_error_list)\n",
    "print(\"\\nMAE:\", MAE_list)\n",
    "print(\"\\nRMSE:\", RMSE_list)\n",
    "print(\"\\nR²:\", R2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c12b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMax. error =\", round(min(max_error_list), 2))\n",
    "print(\"Min. error =\", round(max(max_error_list), 2))\n",
    "print(\"Max. error =\", round(np.mean(max_error_list), 2), \"±\", round(np.std(max_error_list), 2))\n",
    "\n",
    "print(\"\\nMax. relative error = \", 100 * round(min(max_rel_error_list), 2), \" %\", sep='')\n",
    "print(\"Min. relative error = \", 100 * round(max(max_rel_error_list), 2), \" %\", sep='')\n",
    "print(\"Max. relative error = \", 100 * round(np.mean(max_rel_error_list), 2), \" ± \", 100 * round(np.std(max_rel_error_list), 2), \" %\", sep='')\n",
    "\n",
    "print(\"\\nMax. MAE =\", round(max(MAE_list), 2))\n",
    "print(\"Min. MAE =\", round(min(MAE_list), 2))\n",
    "print(\"MAE =\", round(np.mean(MAE_list), 2), \"±\", round(np.std(MAE_list), 2))\n",
    "\n",
    "print(\"\\nMax. RMSE =\", round(max(RMSE_list), 2))\n",
    "print(\"Min. RMSE =\", round(min(RMSE_list), 2))\n",
    "print(\"RMSE =\", round(np.mean(RMSE_list), 2), \"±\", round(np.std(RMSE_list), 2))\n",
    "\n",
    "print(\"\\nMax. R² =\", round(max(R2_list), 2))\n",
    "print(\"Min. R² =\", round(min(R2_list), 2))\n",
    "print(\"R² =\", round(np.mean(R2_list), 2), \"±\", round(np.std(R2_list), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e65dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fim do processamento\n",
    "now = datetime.now()\n",
    "\n",
    "print(now.strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "print(\"\\nTempo de processamento: %s segundos\\n\" % (round((time.time() - start_time), 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
